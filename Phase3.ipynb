{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        " Initialize Spark"
      ],
      "metadata": {
        "id": "MsB2kV1wbl4e"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qednmnmdwRH3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3079ab83-c9aa-4e17-9517-8660c6947b5c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[Transaction ID: string, Country: string, Amount (USD): double, Transaction Type: string, Date of Transaction: string, Person Involved: string, Industry: string, Destination Country: string, Reported by Authority: boolean, Source of Money: string, Money Laundering Risk Score: int, Shell Companies Involved: int, Financial Institution: string, Tax Haven Country: string]"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Initialize Spark session\n",
        "spk = SparkSession.builder \\\n",
        "    .appName(\"BigBlackMoneyAnalysis\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "# Load the dataset\n",
        "ab = spk.read.csv(\"Big_Black_Money_Dataset.csv\", header=True, inferSchema=True)\n",
        "ab"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "DAG Visualizations Code"
      ],
      "metadata": {
        "id": "dPiwRajRcwZL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark findspark pyngrok\n",
        "from pyngrok import ngrok, conf\n",
        "import getpass\n",
        "import findspark\n",
        "findspark.init()\n",
        "# Set up ngrok\n",
        "print(\"Enter your authtoken, which can be copied from https://dashboard.ngrok.com/get-started/your-authtoken\")\n",
        "auth_token = getpass.getpass()\n",
        "conf.get_default().auth_token = auth_token\n",
        "ui_port = 4040\n",
        "\n",
        "try:\n",
        "    # Connect ngrok to Spark UI\n",
        "    public_url = ngrok.connect(ui_port).public_url\n",
        "    print(f\" * ngrok tunnel \\\"{public_url}\\\" -> \\\"http://127.0.0.1:{ui_port}\\\"\")\n",
        "except Exception as e:\n",
        "    print(\"Error setting up ngrok tunnel:\", e)"
      ],
      "metadata": {
        "id": "YcVomDc_vnI1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "288f331d-68b6-431e-f58b-a57d40924a84"
      },
      "execution_count": 16,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.10/dist-packages (3.5.3)\n",
            "Requirement already satisfied: findspark in /usr/local/lib/python3.10/dist-packages (2.0.1)\n",
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.10/dist-packages (7.2.1)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.2)\n",
            "Enter your authtoken, which can be copied from https://dashboard.ngrok.com/get-started/your-authtoken\n",
            "··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pyngrok.process.ngrok:t=2024-11-26T04:01:25+0000 lvl=warn msg=\"can't bind default web address, trying alternatives\" obj=web addr=127.0.0.1:4040\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * ngrok tunnel \"https://fc89-34-75-137-85.ngrok-free.app\" -> \"http://127.0.0.1:4040\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spk.stop()"
      ],
      "metadata": {
        "id": "oyvhkxlXce_1"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!curl http:http://127.0.0.1:4040"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Edt3eFcKtU0n",
        "outputId": "a301dabe-c226-42c8-8a51-79af0ab748a7"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "curl: (3) URL using bad/illegal format or missing URL\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "# Get a list of all active tunnels\n",
        "tunnels = ngrok.get_tunnels()\n",
        "\n",
        "# Disconnect each tunnel\n",
        "for tunnel in tunnels:\n",
        "    ngrok.disconnect(tunnel.public_url)\n",
        "\n",
        "# Kill the ngrok process to ensure all tunnels are closed\n",
        "ngrok.kill()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V7sO7Af5tv7Q",
        "outputId": "3b41314d-4d54-43f7-c3a8-580be91ed1e4"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pyngrok.process.ngrok:t=2024-11-26T03:50:34+0000 lvl=warn msg=\"Stopping forwarder\" name=http-4040-18b44bcc-8eb6-4a02-a194-239fd07eef52 acceptErr=\"failed to accept connection: Listener closed\"\n",
            "WARNING:pyngrok.process.ngrok:t=2024-11-26T03:50:34+0000 lvl=warn msg=\"Stopping forwarder\" name=http-4040-a0484a9b-8b6b-4c23-8d85-f181ec61b41e acceptErr=\"failed to accept connection: Listener closed\"\n",
            "WARNING:pyngrok.process.ngrok:t=2024-11-26T03:50:34+0000 lvl=warn msg=\"Stopping forwarder\" name=http-4040-897fe877-1857-4a7a-ac2e-432fa9961507 acceptErr=\"failed to accept connection: Listener closed\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Distributed datacleaning  or preprocessing"
      ],
      "metadata": {
        "id": "DVomA3Izya2c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. converting date column to timestamp"
      ],
      "metadata": {
        "id": "bU2OHEmQyjN6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col\n",
        "\n",
        "# Convert 'Date of Transaction' to timestamp\n",
        "ab = ab.withColumn(\"Date of Transaction\", col(\"Date of Transaction\").cast(\"timestamp\"))"
      ],
      "metadata": {
        "id": "zmBGGlaLyhI6"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Handling missing Values"
      ],
      "metadata": {
        "id": "oo1pSqkMyrzy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import mean\n",
        "\n",
        "# Impute missing values in 'Amount (USD)' with the mean amount\n",
        "m_amount = ab.select(mean(\"Amount (USD)\")).collect()[0][0]\n",
        "ab = ab.na.fill({\"Amount (USD)\": m_amount})"
      ],
      "metadata": {
        "id": "RBOeyh5oyvpR"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Removing Duplicates"
      ],
      "metadata": {
        "id": "nzD0xaQgy5Pk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove duplicates based on 'Transaction ID'\n",
        "ab = ab.dropDuplicates([\"Transaction ID\"])"
      ],
      "metadata": {
        "id": "sMeytvLSy9F6"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.Detecting and removing Outliers"
      ],
      "metadata": {
        "id": "Gyxse6yfzTl_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "quant = ab.approxQuantile(\"Amount (USD)\", [0.25, 0.75], 0.05)\n",
        "iqr = quant[1] - quant[0]\n",
        "lr_bound = quant[0] - 1.5 * iqr\n",
        "up_bound = quant[1] + 1.5 * iqr\n",
        "\n",
        "# Filter out outliers\n",
        "ab = ab.filter((col(\"Amount (USD)\") >= lr_bound) & (col(\"Amount (USD)\") <= up_bound))"
      ],
      "metadata": {
        "id": "CG9a2r_WzXnk"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Feature Engineering is by creating risk category"
      ],
      "metadata": {
        "id": "c5ybljfFzsqG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import when\n",
        "\n",
        "# Create a new column 'Risk Category' based on 'Money Laundering Risk Score'\n",
        "ab = ab.withColumn(\"Risk Category\", when(col(\"Money Laundering Risk Score\") >= 7, \"High\")\n",
        "                                      .when(col(\"Money Laundering Risk Score\") >= 4, \"Medium\")\n",
        "                                      .otherwise(\"Low\"))"
      ],
      "metadata": {
        "id": "JnKts3X6z05n"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. One-Hot encoding for categorical variables"
      ],
      "metadata": {
        "id": "e4N7fPfmz56m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import functions as F\n",
        "from pyspark.ml.feature import StringIndexer, OneHotEncoder\n",
        "from pyspark.ml import Pipeline\n",
        "\n",
        "# Convert Boolean column to String\n",
        "ab = ab.withColumn(\"Reported by Authority\", F.col(\"Reported by Authority\").cast(\"string\"))\n",
        "\n",
        "# List of categorical columns\n",
        "categorical_columns = [\n",
        "    'Country',\n",
        "    'Transaction Type',\n",
        "    'Person Involved',\n",
        "    'Industry',\n",
        "    'Destination Country',\n",
        "    'Reported by Authority',  # Now converted to string\n",
        "    'Source of Money',\n",
        "    'Shell Companies Involved',\n",
        "    'Financial Institution',\n",
        "    'Tax Haven Country'\n",
        "]\n",
        "\n",
        "# Create stages for the pipeline\n",
        "stages = []\n",
        "\n",
        "for column in categorical_columns:\n",
        "    # Create a StringIndexer for each categorical column\n",
        "    indexer = StringIndexer(inputCol=column, outputCol=f\"{column}Index\")\n",
        "\n",
        "    # Create a OneHotEncoder for each indexed column\n",
        "    encoder = OneHotEncoder(inputCols=[f\"{column}Index\"], outputCols=[f\"{column}Vec\"])\n",
        "\n",
        "    # Add both stages to the list\n",
        "    stages.extend([indexer, encoder])\n",
        "\n",
        "# Create and fit the pipeline\n",
        "pipeline = Pipeline(stages=stages)\n",
        "ab = pipeline.fit(ab).transform(ab)\n",
        "\n",
        "# Show some transformed columns\n",
        "ab.select([f\"{column}Vec\" for column in categorical_columns]).show()\n"
      ],
      "metadata": {
        "id": "IMPsobTz0AKd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49663cce-2dc2-454b-d998-cbecc9a70577"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+-------------------+-------------------+-------------+----------------------+------------------------+------------------+---------------------------+------------------------+--------------------+\n",
            "|   CountryVec|Transaction TypeVec| Person InvolvedVec|  IndustryVec|Destination CountryVec|Reported by AuthorityVec|Source of MoneyVec|Shell Companies InvolvedVec|Financial InstitutionVec|Tax Haven CountryVec|\n",
            "+-------------+-------------------+-------------------+-------------+----------------------+------------------------+------------------+---------------------------+------------------------+--------------------+\n",
            "|(9,[3],[1.0])|      (4,[1],[1.0])|(6285,[5863],[1.0])|(6,[4],[1.0])|         (9,[7],[1.0])|           (1,[0],[1.0])|     (5,[0],[1.0])|              (9,[4],[1.0])|       (498,[282],[1.0])|       (5,[1],[1.0])|\n",
            "|(9,[7],[1.0])|      (4,[0],[1.0])|(6285,[2616],[1.0])|    (6,[],[])|             (9,[],[])|           (1,[0],[1.0])|     (5,[1],[1.0])|              (9,[5],[1.0])|        (498,[65],[1.0])|       (5,[0],[1.0])|\n",
            "|(9,[5],[1.0])|      (4,[0],[1.0])|(6285,[2776],[1.0])|(6,[1],[1.0])|         (9,[5],[1.0])|           (1,[0],[1.0])|     (5,[1],[1.0])|              (9,[2],[1.0])|       (498,[467],[1.0])|       (5,[0],[1.0])|\n",
            "|(9,[3],[1.0])|      (4,[2],[1.0])| (6285,[781],[1.0])|(6,[2],[1.0])|         (9,[0],[1.0])|               (1,[],[])|     (5,[0],[1.0])|              (9,[6],[1.0])|       (498,[377],[1.0])|       (5,[3],[1.0])|\n",
            "|(9,[0],[1.0])|      (4,[1],[1.0])|(6285,[5265],[1.0])|(6,[1],[1.0])|         (9,[4],[1.0])|           (1,[0],[1.0])|     (5,[0],[1.0])|              (9,[0],[1.0])|        (498,[88],[1.0])|       (5,[4],[1.0])|\n",
            "|(9,[2],[1.0])|      (4,[1],[1.0])|(6285,[3689],[1.0])|(6,[2],[1.0])|         (9,[5],[1.0])|               (1,[],[])|     (5,[0],[1.0])|                  (9,[],[])|       (498,[482],[1.0])|           (5,[],[])|\n",
            "|(9,[8],[1.0])|      (4,[3],[1.0])|  (6285,[15],[1.0])|    (6,[],[])|         (9,[2],[1.0])|           (1,[0],[1.0])|     (5,[0],[1.0])|              (9,[2],[1.0])|       (498,[369],[1.0])|       (5,[0],[1.0])|\n",
            "|(9,[1],[1.0])|          (4,[],[])| (6285,[148],[1.0])|(6,[3],[1.0])|         (9,[0],[1.0])|               (1,[],[])|     (5,[0],[1.0])|              (9,[7],[1.0])|       (498,[301],[1.0])|       (5,[1],[1.0])|\n",
            "|(9,[5],[1.0])|      (4,[0],[1.0])|(6285,[3844],[1.0])|(6,[4],[1.0])|             (9,[],[])|           (1,[0],[1.0])|     (5,[1],[1.0])|                  (9,[],[])|       (498,[245],[1.0])|       (5,[2],[1.0])|\n",
            "|(9,[7],[1.0])|      (4,[0],[1.0])|(6285,[1041],[1.0])|    (6,[],[])|             (9,[],[])|           (1,[0],[1.0])|     (5,[1],[1.0])|              (9,[5],[1.0])|        (498,[65],[1.0])|       (5,[0],[1.0])|\n",
            "|(9,[8],[1.0])|      (4,[0],[1.0])| (6285,[402],[1.0])|(6,[3],[1.0])|         (9,[7],[1.0])|           (1,[0],[1.0])|     (5,[0],[1.0])|              (9,[1],[1.0])|       (498,[390],[1.0])|       (5,[1],[1.0])|\n",
            "|(9,[3],[1.0])|          (4,[],[])|(6285,[2417],[1.0])|(6,[4],[1.0])|         (9,[1],[1.0])|           (1,[0],[1.0])|     (5,[0],[1.0])|              (9,[4],[1.0])|        (498,[27],[1.0])|       (5,[0],[1.0])|\n",
            "|(9,[0],[1.0])|      (4,[2],[1.0])| (6285,[731],[1.0])|(6,[4],[1.0])|         (9,[6],[1.0])|           (1,[0],[1.0])|     (5,[0],[1.0])|              (9,[0],[1.0])|       (498,[459],[1.0])|           (5,[],[])|\n",
            "|(9,[1],[1.0])|      (4,[2],[1.0])|(6285,[3518],[1.0])|(6,[5],[1.0])|         (9,[4],[1.0])|               (1,[],[])|     (5,[1],[1.0])|              (9,[6],[1.0])|        (498,[80],[1.0])|       (5,[2],[1.0])|\n",
            "|(9,[7],[1.0])|      (4,[1],[1.0])|(6285,[5909],[1.0])|(6,[4],[1.0])|         (9,[7],[1.0])|           (1,[0],[1.0])|     (5,[1],[1.0])|              (9,[6],[1.0])|       (498,[175],[1.0])|           (5,[],[])|\n",
            "|(9,[3],[1.0])|      (4,[1],[1.0])|(6285,[1880],[1.0])|(6,[3],[1.0])|             (9,[],[])|           (1,[0],[1.0])|     (5,[0],[1.0])|              (9,[8],[1.0])|        (498,[13],[1.0])|       (5,[2],[1.0])|\n",
            "|(9,[1],[1.0])|      (4,[0],[1.0])|(6285,[1209],[1.0])|(6,[3],[1.0])|         (9,[3],[1.0])|           (1,[0],[1.0])|     (5,[0],[1.0])|                  (9,[],[])|       (498,[229],[1.0])|       (5,[1],[1.0])|\n",
            "|(9,[2],[1.0])|      (4,[1],[1.0])| (6285,[147],[1.0])|(6,[2],[1.0])|         (9,[6],[1.0])|           (1,[0],[1.0])|     (5,[1],[1.0])|              (9,[1],[1.0])|         (498,[7],[1.0])|           (5,[],[])|\n",
            "|(9,[0],[1.0])|      (4,[2],[1.0])|(6285,[1693],[1.0])|(6,[3],[1.0])|             (9,[],[])|               (1,[],[])|     (5,[0],[1.0])|              (9,[4],[1.0])|        (498,[33],[1.0])|       (5,[0],[1.0])|\n",
            "|(9,[7],[1.0])|      (4,[1],[1.0])|(6285,[2319],[1.0])|(6,[3],[1.0])|         (9,[4],[1.0])|               (1,[],[])|     (5,[0],[1.0])|              (9,[6],[1.0])|       (498,[438],[1.0])|           (5,[],[])|\n",
            "+-------------+-------------------+-------------------+-------------+----------------------+------------------------+------------------+---------------------------+------------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Normalizing the Amount (USD)"
      ],
      "metadata": {
        "id": "1vAI16pq0QT9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import DoubleType\n",
        "from pyspark.ml.feature import MinMaxScaler, VectorAssembler\n",
        "\n",
        "# Ensure the column is numeric\n",
        "ab = ab.withColumn(\"Amount (USD)\", ab[\"Amount (USD)\"].cast(DoubleType()))\n",
        "\n",
        "# Handle nulls if necessary\n",
        "ab = ab.na.drop(subset=[\"Amount (USD)\"])\n",
        "\n",
        "# Assemble the vector\n",
        "ass = VectorAssembler(inputCols=[\"Amount (USD)\"], outputCol=\"AmountVec\")\n",
        "ab = ass.transform(ab)\n",
        "\n",
        "# Check the output of the assembler\n",
        "ab.select(\"AmountVec\").show(truncate=False)\n",
        "\n",
        "# Apply MinMaxScaler\n",
        "sclr = MinMaxScaler(inputCol=\"AmountVec\", outputCol=\"NormalizedAmount\")\n",
        "ab = sclr.fit(ab).transform(ab)\n",
        "\n",
        "# Check the final output\n",
        "ab.select(\"NormalizedAmount\").show(truncate=False)\n"
      ],
      "metadata": {
        "id": "Nnf2Oyxk0U6L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2bdd460e-c425-4cad-80d4-c3dc747c8896"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+\n",
            "|AmountVec    |\n",
            "+-------------+\n",
            "|[3267530.479]|\n",
            "|[4965766.725]|\n",
            "|[94167.50048]|\n",
            "|[386420.1412]|\n",
            "|[643378.4264]|\n",
            "|[4921056.454]|\n",
            "|[3262817.984]|\n",
            "|[4687204.61] |\n",
            "|[903905.9486]|\n",
            "|[4174994.676]|\n",
            "|[2675518.773]|\n",
            "|[3370300.35] |\n",
            "|[729587.7725]|\n",
            "|[2973516.598]|\n",
            "|[3669888.192]|\n",
            "|[3740050.645]|\n",
            "|[3262817.984]|\n",
            "|[3865495.571]|\n",
            "|[2168678.373]|\n",
            "|[1486877.067]|\n",
            "+-------------+\n",
            "only showing top 20 rows\n",
            "\n",
            "+---------------------+\n",
            "|NormalizedAmount     |\n",
            "+---------------------+\n",
            "|[0.6535306150923231] |\n",
            "|[0.9931906077238586] |\n",
            "|[0.01883420672153462]|\n",
            "|[0.07728692790641858]|\n",
            "|[0.12868051314122814]|\n",
            "|[0.9842482180214933] |\n",
            "|[0.6525880807301304] |\n",
            "|[0.9374760944156055] |\n",
            "|[0.18078797255931206]|\n",
            "|[0.835030264032452]  |\n",
            "|[0.5351238314829343] |\n",
            "|[0.6740853604693712] |\n",
            "|[0.1459230292693967] |\n",
            "|[0.5947256326352304] |\n",
            "|[0.7340051769530299] |\n",
            "|[0.7480381940465719] |\n",
            "|[0.6525880807301304] |\n",
            "|[0.7731281205754533] |\n",
            "|[0.4337519481923427] |\n",
            "|[0.2973865708088409] |\n",
            "+---------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. Aggeration Transactions per Persons"
      ],
      "metadata": {
        "id": "UUPpjXbW0jpn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import count, sum\n",
        "\n",
        "# Aggregate number of transactions and total amount per person\n",
        "prsn_agg_ab = ab.groupBy(\"Person Involved\").agg(\n",
        "    count(\"*\").alias(\"Num_Transactions\"),\n",
        "    sum(\"Amount (USD)\").alias(\"Total_Amount\")\n",
        ")"
      ],
      "metadata": {
        "id": "DZ-eBlMF0oO1"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. Windowing Function for Rolling Average Amount"
      ],
      "metadata": {
        "id": "66MN-OTu0x0X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.window import Window\n",
        "from pyspark.sql.functions import avg\n",
        "\n",
        "winspec = Window.partitionBy(\"Country\").orderBy(\"Date of Transaction\").rowsBetween(-3, 0)\n",
        "\n",
        "# Calculate rolling average amount for each country over last 4 transactions\n",
        "ab= ab.withColumn(\"Rolling_Avg_Amount\", avg(\"Amount (USD)\").over(winspec))"
      ],
      "metadata": {
        "id": "yq2Ll_vV03kC"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. Splitting the dataset into train and test"
      ],
      "metadata": {
        "id": "216Z-f2d1Azv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, test_data = ab.randomSplit([0.8, 0.2], seed=42)"
      ],
      "metadata": {
        "id": "gxisQheP1Fli"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Machine Learning Algorithms with PySpark**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "jk8wImTH1Ndi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "execution_times = []\n",
        "precisions = []\n",
        "accuracies = []\n",
        "f1_scores = []\n",
        "recalls = []"
      ],
      "metadata": {
        "id": "v0U0kv5ogCdf"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Logistic Regression"
      ],
      "metadata": {
        "id": "U3qJXOayiBiM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import StringIndexer, VectorAssembler, OneHotEncoder\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col\n",
        "import time\n",
        "\n",
        "spark = SparkSession.builder.appName(\"MoneyLaunderingModel\").getOrCreate()\n",
        "data = spark.read.csv(\"/content/Big_Black_Money_Dataset.csv\", header=True, inferSchema=True)\n",
        "data = data.drop(\"features\").dropna()\n",
        "data = data.withColumn(\"Reported by Authority\", col(\"Reported by Authority\").cast(\"int\"))\n",
        "\n",
        "categorical_columns = ['Transaction Type', 'Person Involved', 'Industry',\n",
        "                       'Destination Country', 'Source of Money', 'Financial Institution', 'Tax Haven Country']\n",
        "numerical_columns = ['Amount (USD)', 'Shell Companies Involved']\n",
        "\n",
        "indexers = [StringIndexer(inputCol=col, outputCol=col + \"_index\") for col in categorical_columns]\n",
        "encoders = [OneHotEncoder(inputCol=col + \"_index\", outputCol=col + \"_onehot\") for col in categorical_columns]\n",
        "assembler_input = numerical_columns + [col + \"_onehot\" for col in categorical_columns]\n",
        "assembler = VectorAssembler(inputCols=assembler_input, outputCol='features')\n",
        "log_reg = LogisticRegression(featuresCol='features', labelCol='Reported by Authority')\n",
        "pipeline = Pipeline(stages=indexers + encoders + [assembler, log_reg])\n",
        "\n",
        "execution_times = []\n",
        "start_time = time.time()\n",
        "\n",
        "try:\n",
        "    model = pipeline.fit(data)\n",
        "except Exception as e:\n",
        "    print(\"Error during pipeline fitting:\", e)\n",
        "\n",
        "predictions_log_reg = model.transform(data)\n",
        "end_time = time.time()\n",
        "execution_time = end_time - start_time\n",
        "\n",
        "confusion_matrix = predictions_log_reg.groupBy('Reported by Authority', 'prediction').count().orderBy('Reported by Authority', 'prediction')\n",
        "print(\"Confusion Matrix:\")\n",
        "confusion_matrix.show()\n",
        "\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol='Reported by Authority', predictionCol='prediction')\n",
        "\n",
        "accuracy = evaluator.evaluate(predictions_log_reg)\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "precision = evaluator.evaluate(predictions_log_reg, {evaluator.metricName: \"weightedPrecision\"})\n",
        "recall = evaluator.evaluate(predictions_log_reg, {evaluator.metricName: \"weightedRecall\"})\n",
        "f1_score = evaluator.evaluate(predictions_log_reg, {evaluator.metricName: \"f1\"})\n",
        "\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1_score:.4f}\")\n",
        "\n",
        "execution_times.append(execution_time)\n",
        "print(f\"Execution Time: {execution_time} seconds\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UMV2iXaRJBKR",
        "outputId": "31776797-e412-4710-cd82-c156014e16df"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "+---------------------+----------+-----+\n",
            "|Reported by Authority|prediction|count|\n",
            "+---------------------+----------+-----+\n",
            "|                    0|       0.0| 7648|\n",
            "|                    0|       1.0|  226|\n",
            "|                    1|       0.0|  270|\n",
            "|                    1|       1.0| 1701|\n",
            "+---------------------+----------+-----+\n",
            "\n",
            "Accuracy: 0.9494\n",
            "Precision: 0.9492\n",
            "Recall: 0.9496\n",
            "F1 Score: 0.9494\n",
            "Execution Time: 21.83720302581787 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Naive Bayes"
      ],
      "metadata": {
        "id": "82tfJin4kKtQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import VectorAssembler, StringIndexer, OneHotEncoder\n",
        "from pyspark.ml.classification import NaiveBayes\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.sql import SparkSession\n",
        "import time\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
        "\n",
        "spark = SparkSession.builder.appName(\"MoneyLaunderingModel\").getOrCreate()\n",
        "data = spark.read.csv(\"/content/Big_Black_Money_Dataset.csv\", header=True, inferSchema=True)\n",
        "data = data.drop(\"features\").dropna()\n",
        "categorical_columns = ['Transaction Type', 'Person Involved', 'Industry',\n",
        "                       'Destination Country', 'Source of Money', 'Financial Institution', 'Tax Haven Country']\n",
        "numerical_columns = ['Amount (USD)', 'Money Laundering Risk Score', 'Shell Companies Involved']\n",
        "indexers = [StringIndexer(inputCol=col, outputCol=col + \"_index\") for col in categorical_columns]\n",
        "encoders = [OneHotEncoder(inputCol=col + \"_index\", outputCol=col + \"_onehot\") for col in categorical_columns]\n",
        "assembler_input = numerical_columns + [col + \"_onehot\" for col in categorical_columns]\n",
        "assembler = VectorAssembler(inputCols=assembler_input, outputCol='features')\n",
        "nb = NaiveBayes(featuresCol='features', labelCol='Money Laundering Risk Score', modelType=\"multinomial\")\n",
        "pipeline = Pipeline(stages=indexers + encoders + [assembler, nb])\n",
        "execution_times = []\n",
        "start_time = time.time()\n",
        "\n",
        "try:\n",
        "    model = pipeline.fit(data)\n",
        "except Exception as e:\n",
        "    print(\"Error during pipeline fitting:\", e)\n",
        "\n",
        "predictions_nb = model.transform(data)\n",
        "end_time = time.time()\n",
        "execution_time = end_time - start_time\n",
        "\n",
        "confusion_matrix = predictions_nb.groupBy('Money Laundering Risk Score', 'prediction').count().orderBy('Money Laundering Risk Score', 'prediction')\n",
        "print(\"Confusion Matrix:\")\n",
        "confusion_matrix.show()\n",
        "\n",
        "evaluator = BinaryClassificationEvaluator(labelCol='Money Laundering Risk Score', rawPredictionCol='prediction')\n",
        "accuracy = evaluator.evaluate(predictions_nb)\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "execution_times.append(execution_time)\n",
        "print(f\"Execution Time: {execution_time} seconds\")\n",
        "\n",
        "evaluator_precision = MulticlassClassificationEvaluator(\n",
        "    labelCol=\"Money Laundering Risk Score\",\n",
        "    predictionCol=\"prediction\",\n",
        "    metricName=\"weightedPrecision\"\n",
        ")\n",
        "precision = evaluator_precision.evaluate(predictions_nb)\n",
        "print(f\"Precision: {precision:.2f}\")\n",
        "\n",
        "evaluator_recall = MulticlassClassificationEvaluator(\n",
        "    labelCol=\"Money Laundering Risk Score\",\n",
        "    predictionCol=\"prediction\",\n",
        "    metricName=\"weightedRecall\"\n",
        ")\n",
        "recall = evaluator_recall.evaluate(predictions_nb)\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "\n",
        "evaluator_f1 = MulticlassClassificationEvaluator(\n",
        "    labelCol=\"Money Laundering Risk Score\",\n",
        "    predictionCol=\"prediction\",\n",
        "    metricName=\"f1\"\n",
        ")\n",
        "f1_score = evaluator_f1.evaluate(predictions_nb)\n",
        "print(f\"F1 Score: {f1_score:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ziaTH_WqedKN",
        "outputId": "a37b201f-4b2d-402c-9566-9539550b612e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Transaction ID: string (nullable = true)\n",
            " |-- Country: string (nullable = true)\n",
            " |-- Amount (USD): double (nullable = true)\n",
            " |-- Transaction Type: string (nullable = true)\n",
            " |-- Date of Transaction: string (nullable = true)\n",
            " |-- Person Involved: string (nullable = true)\n",
            " |-- Industry: string (nullable = true)\n",
            " |-- Destination Country: string (nullable = true)\n",
            " |-- Reported by Authority: boolean (nullable = true)\n",
            " |-- Source of Money: string (nullable = true)\n",
            " |-- Money Laundering Risk Score: integer (nullable = true)\n",
            " |-- Shell Companies Involved: integer (nullable = true)\n",
            " |-- Financial Institution: string (nullable = true)\n",
            " |-- Tax Haven Country: string (nullable = true)\n",
            "\n",
            "Confusion Matrix:\n",
            "+---------------------------+----------+-----+\n",
            "|Money Laundering Risk Score|prediction|count|\n",
            "+---------------------------+----------+-----+\n",
            "|                          0|       1.0|    6|\n",
            "|                          0|       4.0|    1|\n",
            "|                          1|       1.0|  862|\n",
            "|                          1|       2.0|   14|\n",
            "|                          1|       3.0|   25|\n",
            "|                          1|       4.0|    7|\n",
            "|                          1|       5.0|   36|\n",
            "|                          1|       6.0|   13|\n",
            "|                          1|       7.0|   15|\n",
            "|                          1|       8.0|   22|\n",
            "|                          1|       9.0|    3|\n",
            "|                          1|      10.0|   16|\n",
            "|                          2|       1.0|  125|\n",
            "|                          2|       2.0|  496|\n",
            "|                          2|       3.0|  115|\n",
            "|                          2|       4.0|   44|\n",
            "|                          2|       5.0|   26|\n",
            "|                          2|       6.0|   19|\n",
            "|                          2|       7.0|   23|\n",
            "|                          2|       8.0|   22|\n",
            "+---------------------------+----------+-----+\n",
            "only showing top 20 rows\n",
            "\n",
            "Accuracy: 0.9030\n",
            "Execution Time: 9.200909852981567 seconds\n",
            "Precision: 0.59\n",
            "Recall: 0.54\n",
            "F1 Score: 0.53\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Support Vector Machine"
      ],
      "metadata": {
        "id": "vPJddBnNn9nX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import StringIndexer, VectorAssembler, OneHotEncoder\n",
        "from pyspark.ml.classification import LinearSVC\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col\n",
        "import time\n",
        "\n",
        "spark = SparkSession.builder.appName(\"MoneyLaunderingModel\").getOrCreate()\n",
        "data = spark.read.csv(\"/content/Big_Black_Money_Dataset.csv\", header=True, inferSchema=True)\n",
        "data = data.drop(\"features\").dropna()\n",
        "data = data.withColumn(\"Reported by Authority\", col(\"Reported by Authority\").cast(\"int\"))\n",
        "\n",
        "categorical_columns = ['Transaction Type', 'Person Involved', 'Industry',\n",
        "                       'Destination Country', 'Source of Money', 'Financial Institution', 'Tax Haven Country']\n",
        "numerical_columns = ['Amount (USD)', 'Shell Companies Involved']\n",
        "\n",
        "indexers = [StringIndexer(inputCol=col, outputCol=col + \"_index\") for col in categorical_columns]\n",
        "encoders = [OneHotEncoder(inputCol=col + \"_index\", outputCol=col + \"_onehot\") for col in categorical_columns]\n",
        "assembler_input = numerical_columns + [col + \"_onehot\" for col in categorical_columns]\n",
        "assembler = VectorAssembler(inputCols=assembler_input, outputCol='features')\n",
        "svm = LinearSVC(featuresCol='features', labelCol='Reported by Authority')\n",
        "pipeline = Pipeline(stages=indexers + encoders + [assembler, svm])\n",
        "\n",
        "execution_times = []\n",
        "start_time = time.time()\n",
        "\n",
        "try:\n",
        "    model = pipeline.fit(data)\n",
        "except Exception as e:\n",
        "    print(\"Error during pipeline fitting:\", e)\n",
        "\n",
        "predictions_svm = model.transform(data)\n",
        "end_time = time.time()\n",
        "execution_time = end_time - start_time\n",
        "\n",
        "confusion_matrix = predictions_svm.groupBy('Reported by Authority', 'prediction').count().orderBy('Reported by Authority', 'prediction')\n",
        "print(\"Confusion Matrix:\")\n",
        "confusion_matrix.show()\n",
        "\n",
        "evaluator = BinaryClassificationEvaluator(labelCol='Reported by Authority', rawPredictionCol='prediction')\n",
        "accuracy = evaluator.evaluate(predictions_svm)\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "execution_times.append(execution_time)\n",
        "print(f\"Execution Time: {execution_time} seconds\")\n",
        "\n",
        "evaluator_precision = MulticlassClassificationEvaluator(\n",
        "    labelCol=\"Reported by Authority\",\n",
        "    predictionCol=\"prediction\",\n",
        "    metricName=\"weightedPrecision\"\n",
        ")\n",
        "precision = evaluator_precision.evaluate(predictions_svm)\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "\n",
        "evaluator_recall = MulticlassClassificationEvaluator(\n",
        "    labelCol=\"Reported by Authority\",\n",
        "    predictionCol=\"prediction\",\n",
        "    metricName=\"weightedRecall\"\n",
        ")\n",
        "recall = evaluator_recall.evaluate(predictions_svm)\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "\n",
        "evaluator_f1 = MulticlassClassificationEvaluator(\n",
        "    labelCol=\"Reported by Authority\",\n",
        "    predictionCol=\"prediction\",\n",
        "    metricName=\"f1\"\n",
        ")\n",
        "f1_score = evaluator_f1.evaluate(predictions_svm)\n",
        "print(f\"F1 Score: {f1_score:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m3hRjrKpCgSB",
        "outputId": "cf962a23-1cbf-4e75-fe22-601f2b39a2cc"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "+---------------------+----------+-----+\n",
            "|Reported by Authority|prediction|count|\n",
            "+---------------------+----------+-----+\n",
            "|                    0|       0.0| 7722|\n",
            "|                    0|       1.0|  152|\n",
            "|                    1|       0.0|  274|\n",
            "|                    1|       1.0| 1697|\n",
            "+---------------------+----------+-----+\n",
            "\n",
            "Accuracy: 0.9208\n",
            "Execution Time: 30.536436319351196 seconds\n",
            "Precision: 0.9561\n",
            "Recall: 0.9567\n",
            "F1 Score: 0.9562\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.KNN"
      ],
      "metadata": {
        "id": "NXrYLoeFqZkR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import StringIndexer, VectorAssembler, OneHotEncoder\n",
        "from pyspark.ml.classification import LinearSVC\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col\n",
        "import time\n",
        "\n",
        "spark = SparkSession.builder.appName(\"MoneyLaunderingModel\").getOrCreate()\n",
        "data = spark.read.csv(\"/content/Big_Black_Money_Dataset.csv\", header=True, inferSchema=True)\n",
        "data = data.drop(\"features\").dropna()\n",
        "data = data.withColumn(\"Reported by Authority\", col(\"Reported by Authority\").cast(\"int\"))\n",
        "\n",
        "categorical_columns = ['Transaction Type', 'Person Involved', 'Industry',\n",
        "                       'Destination Country', 'Source of Money', 'Financial Institution', 'Tax Haven Country']\n",
        "numerical_columns = ['Amount (USD)', 'Shell Companies Involved']\n",
        "\n",
        "indexers = [StringIndexer(inputCol=col, outputCol=col + \"_index\") for col in categorical_columns]\n",
        "encoders = [OneHotEncoder(inputCol=col + \"_index\", outputCol=col + \"_onehot\") for col in categorical_columns]\n",
        "assembler_input = numerical_columns + [col + \"_onehot\" for col in categorical_columns]\n",
        "assembler = VectorAssembler(inputCols=assembler_input, outputCol='features')\n",
        "svm = LinearSVC(featuresCol='features', labelCol='Reported by Authority')\n",
        "pipeline = Pipeline(stages=indexers + encoders + [assembler, svm])\n",
        "\n",
        "execution_times = []\n",
        "start_time = time.time()\n",
        "\n",
        "try:\n",
        "    model = pipeline.fit(data)\n",
        "except Exception as e:\n",
        "    print(\"Error during pipeline fitting:\", e)\n",
        "\n",
        "predictions_svm = model.transform(data)\n",
        "end_time = time.time()\n",
        "execution_time = end_time - start_time\n",
        "\n",
        "confusion_matrix = predictions_svm.groupBy('Reported by Authority', 'prediction').count().orderBy('Reported by Authority', 'prediction')\n",
        "print(\"Confusion Matrix:\")\n",
        "confusion_matrix.show()\n",
        "\n",
        "evaluator = BinaryClassificationEvaluator(labelCol='Reported by Authority', rawPredictionCol='prediction')\n",
        "accuracy = evaluator.evaluate(predictions_svm)\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "execution_times.append(execution_time)\n",
        "print(f\"Execution Time: {execution_time} seconds\")\n",
        "\n",
        "evaluator_precision = MulticlassClassificationEvaluator(\n",
        "    labelCol=\"Reported by Authority\",\n",
        "    predictionCol=\"prediction\",\n",
        "    metricName=\"weightedPrecision\"\n",
        ")\n",
        "precision = evaluator_precision.evaluate(predictions_svm)\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "\n",
        "evaluator_recall = MulticlassClassificationEvaluator(\n",
        "    labelCol=\"Reported by Authority\",\n",
        "    predictionCol=\"prediction\",\n",
        "    metricName=\"weightedRecall\"\n",
        ")\n",
        "recall = evaluator_recall.evaluate(predictions_svm)\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "\n",
        "evaluator_f1 = MulticlassClassificationEvaluator(\n",
        "    labelCol=\"Reported by Authority\",\n",
        "    predictionCol=\"prediction\",\n",
        "    metricName=\"f1\"\n",
        ")\n",
        "f1_score = evaluator_f1.evaluate(predictions_svm)\n",
        "print(f\"F1 Score: {f1_score:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bKe1NlLNJQAA",
        "outputId": "c35cf0e9-f254-4407-b3c5-3a6fd41006b1"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "+---------------------+----------+-----+\n",
            "|Reported by Authority|prediction|count|\n",
            "+---------------------+----------+-----+\n",
            "|                    0|       0.0| 7722|\n",
            "|                    0|       1.0|  152|\n",
            "|                    1|       0.0|  274|\n",
            "|                    1|       1.0| 1697|\n",
            "+---------------------+----------+-----+\n",
            "\n",
            "Accuracy: 0.9208\n",
            "Execution Time: 21.688189268112183 seconds\n",
            "Precision: 0.9561\n",
            "Recall: 0.9567\n",
            "F1 Score: 0.9562\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5.SGD"
      ],
      "metadata": {
        "id": "E0Hpud3kqcCE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import StringIndexer, VectorAssembler, OneHotEncoder\n",
        "from pyspark.ml.classification import LinearSVC\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col\n",
        "import time\n",
        "\n",
        "spark = SparkSession.builder.appName(\"MoneyLaunderingModel\").getOrCreate()\n",
        "data = spark.read.csv(\"/content/Big_Black_Money_Dataset.csv\", header=True, inferSchema=True)\n",
        "data = data.drop(\"features\").dropna()\n",
        "data = data.withColumn(\"Reported by Authority\", col(\"Reported by Authority\").cast(\"int\"))\n",
        "\n",
        "categorical_columns = ['Transaction Type', 'Person Involved', 'Industry',\n",
        "                       'Destination Country', 'Source of Money', 'Financial Institution', 'Tax Haven Country']\n",
        "numerical_columns = ['Amount (USD)', 'Shell Companies Involved']\n",
        "\n",
        "indexers = [StringIndexer(inputCol=col, outputCol=col + \"_index\") for col in categorical_columns]\n",
        "encoders = [OneHotEncoder(inputCol=col + \"_index\", outputCol=col + \"_onehot\") for col in categorical_columns]\n",
        "assembler_input = numerical_columns + [col + \"_onehot\" for col in categorical_columns]\n",
        "assembler = VectorAssembler(inputCols=assembler_input, outputCol='features')\n",
        "svm = LinearSVC(featuresCol='features', labelCol='Reported by Authority')\n",
        "pipeline = Pipeline(stages=indexers + encoders + [assembler, svm])\n",
        "\n",
        "execution_times = []\n",
        "start_time = time.time()\n",
        "\n",
        "try:\n",
        "    model = pipeline.fit(data)\n",
        "except Exception as e:\n",
        "    print(\"Error during pipeline fitting:\", e)\n",
        "\n",
        "predictions_svm = model.transform(data)\n",
        "end_time = time.time()\n",
        "execution_time = end_time - start_time\n",
        "\n",
        "confusion_matrix = predictions_svm.groupBy('Reported by Authority', 'prediction').count().orderBy('Reported by Authority', 'prediction')\n",
        "print(\"Confusion Matrix:\")\n",
        "confusion_matrix.show()\n",
        "\n",
        "evaluator = BinaryClassificationEvaluator(labelCol='Reported by Authority', rawPredictionCol='prediction')\n",
        "accuracy = evaluator.evaluate(predictions_svm)\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "execution_times.append(execution_time)\n",
        "print(f\"Execution Time: {execution_time} seconds\")\n",
        "\n",
        "evaluator_precision = MulticlassClassificationEvaluator(\n",
        "    labelCol=\"Reported by Authority\",\n",
        "    predictionCol=\"prediction\",\n",
        "    metricName=\"weightedPrecision\"\n",
        ")\n",
        "precision = evaluator_precision.evaluate(predictions_svm)\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "\n",
        "evaluator_recall = MulticlassClassificationEvaluator(\n",
        "    labelCol=\"Reported by Authority\",\n",
        "    predictionCol=\"prediction\",\n",
        "    metricName=\"weightedRecall\"\n",
        ")\n",
        "recall = evaluator_recall.evaluate(predictions_svm)\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "\n",
        "evaluator_f1 = MulticlassClassificationEvaluator(\n",
        "    labelCol=\"Reported by Authority\",\n",
        "    predictionCol=\"prediction\",\n",
        "    metricName=\"f1\"\n",
        ")\n",
        "f1_score = evaluator_f1.evaluate(predictions_svm)\n",
        "print(f\"F1 Score: {f1_score:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jR9RvJJHMt9m",
        "outputId": "276df6f9-8fb8-429a-f802-e7c011e9de70"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "+---------------------+----------+-----+\n",
            "|Reported by Authority|prediction|count|\n",
            "+---------------------+----------+-----+\n",
            "|                    0|       0.0| 7722|\n",
            "|                    0|       1.0|  152|\n",
            "|                    1|       0.0|  274|\n",
            "|                    1|       1.0| 1697|\n",
            "+---------------------+----------+-----+\n",
            "\n",
            "Accuracy: 0.9208\n",
            "Execution Time: 24.58067297935486 seconds\n",
            "Precision: 0.9561\n",
            "Recall: 0.9567\n",
            "F1 Score: 0.9562\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6.MLP"
      ],
      "metadata": {
        "id": "5iWnBKzEqd_E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col\n",
        "from pyspark.ml.feature import StringIndexer, VectorAssembler, OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "spark = SparkSession.builder.appName(\"MLP_MoneyLaundering\").getOrCreate()\n",
        "data = spark.read.csv(\"/content/Big_Black_Money_Dataset.csv\", header=True, inferSchema=True)\n",
        "data = data.drop(\"features\").dropna()\n",
        "data = data.withColumn(\"Reported by Authority\", col(\"Reported by Authority\").cast(\"int\"))\n",
        "\n",
        "categorical_columns = ['Transaction Type', 'Person Involved', 'Industry',\n",
        "                       'Destination Country', 'Source of Money', 'Financial Institution', 'Tax Haven Country']\n",
        "numerical_columns = ['Amount (USD)', 'Shell Companies Involved']\n",
        "\n",
        "indexers = [StringIndexer(inputCol=col, outputCol=col + \"_index\") for col in categorical_columns]\n",
        "encoders = [OneHotEncoder(inputCol=col + \"_index\", outputCol=col + \"_onehot\") for col in categorical_columns]\n",
        "assembler_input = numerical_columns + [col + \"_onehot\" for col in categorical_columns]\n",
        "assembler = VectorAssembler(inputCols=assembler_input, outputCol='features')\n",
        "\n",
        "from pyspark.ml import Pipeline\n",
        "pipeline = Pipeline(stages=indexers + encoders + [assembler])\n",
        "data_transformed = pipeline.fit(data).transform(data)\n",
        "\n",
        "data_pandas = data_transformed.select(\"features\", \"Reported by Authority\").toPandas()\n",
        "X = np.array([row.features.toArray() for row in data_pandas.itertuples()])\n",
        "y = np.array(data_pandas['Reported by Authority'])\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "mlp = MLPClassifier(hidden_layer_sizes=(64, 32), max_iter=500, random_state=42, solver='adam', alpha=0.001)\n",
        "mlp.fit(X_train, y_train)\n",
        "y_pred = mlp.predict(X_test)\n",
        "\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(f\"\\nAccuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "print(f\"Precision: {precision_score(y_test, y_pred):.4f}\")\n",
        "print(f\"Recall: {recall_score(y_test, y_pred):.4f}\")\n",
        "print(f\"F1 Score: {f1_score(y_test, y_pred):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oBVljvmENKgV",
        "outputId": "b231bbaa-7338-49b2-c303-6dad0050dff3"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "[[1564    1]\n",
            " [ 404    0]]\n",
            "\n",
            "Accuracy: 0.7943\n",
            "Precision: 0.0000\n",
            "Recall: 0.0000\n",
            "F1 Score: 0.0000\n"
          ]
        }
      ]
    }
  ]
}